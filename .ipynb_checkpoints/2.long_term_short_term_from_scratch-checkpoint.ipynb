{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the raw dataset\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create mapping of characters to integers (0-25) and the reverse\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> B\n",
      "B -> C\n",
      "C -> D\n",
      "D -> E\n",
      "E -> F\n",
      "F -> G\n",
      "G -> H\n",
      "H -> I\n",
      "I -> J\n",
      "J -> K\n",
      "K -> L\n",
      "L -> M\n",
      "M -> N\n",
      "N -> O\n",
      "O -> P\n",
      "P -> Q\n",
      "Q -> R\n",
      "R -> S\n",
      "S -> T\n",
      "T -> U\n",
      "U -> V\n",
      "V -> W\n",
      "W -> X\n",
      "X -> Y\n",
      "Y -> Z\n"
     ]
    }
   ],
   "source": [
    "seq_length = 6\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "\tseq_in = alphabet[i:i + seq_length]\n",
    "\tseq_out = alphabet[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "\tprint seq_in, '->', seq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0],\n",
       "  [1],\n",
       "  [2],\n",
       "  [3],\n",
       "  [4],\n",
       "  [5],\n",
       "  [6],\n",
       "  [7],\n",
       "  [8],\n",
       "  [9],\n",
       "  [10],\n",
       "  [11],\n",
       "  [12],\n",
       "  [13],\n",
       "  [14],\n",
       "  [15],\n",
       "  [16],\n",
       "  [17],\n",
       "  [18],\n",
       "  [19],\n",
       "  [20],\n",
       "  [21],\n",
       "  [22],\n",
       "  [23],\n",
       "  [24]],\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 1, 1), (25, 26))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                858       \n",
      "=================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 2s - loss: 3.2618 - acc: 0.0400\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.2537 - acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.2506 - acc: 0.0400\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.2477 - acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.2449 - acc: 0.0400\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.2419 - acc: 0.0400\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.2388 - acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.2353 - acc: 0.0400\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.2323 - acc: 0.0400\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.2286 - acc: 0.0400\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.2246 - acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.2208 - acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.2173 - acc: 0.0400\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.2125 - acc: 0.0400\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.2075 - acc: 0.0400\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.2032 - acc: 0.0400\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.1975 - acc: 0.0400\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.1920 - acc: 0.0400\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.1865 - acc: 0.0400\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.1800 - acc: 0.0400\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.1739 - acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.1668 - acc: 0.0400\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.1603 - acc: 0.0400\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.1530 - acc: 0.0400\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.1457 - acc: 0.0800\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.1375 - acc: 0.0400\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.1294 - acc: 0.0800\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.1208 - acc: 0.0400\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.1118 - acc: 0.0400\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.1027 - acc: 0.0800\n",
      "Epoch 31/500\n",
      " - 0s - loss: 3.0936 - acc: 0.0800\n",
      "Epoch 32/500\n",
      " - 0s - loss: 3.0826 - acc: 0.0400\n",
      "Epoch 33/500\n",
      " - 0s - loss: 3.0735 - acc: 0.0400\n",
      "Epoch 34/500\n",
      " - 0s - loss: 3.0635 - acc: 0.0400\n",
      "Epoch 35/500\n",
      " - 0s - loss: 3.0522 - acc: 0.0800\n",
      "Epoch 36/500\n",
      " - 0s - loss: 3.0404 - acc: 0.0800\n",
      "Epoch 37/500\n",
      " - 0s - loss: 3.0289 - acc: 0.0800\n",
      "Epoch 38/500\n",
      " - 0s - loss: 3.0182 - acc: 0.0800\n",
      "Epoch 39/500\n",
      " - 0s - loss: 3.0060 - acc: 0.0800\n",
      "Epoch 40/500\n",
      " - 0s - loss: 2.9935 - acc: 0.0800\n",
      "Epoch 41/500\n",
      " - 0s - loss: 2.9811 - acc: 0.0400\n",
      "Epoch 42/500\n",
      " - 0s - loss: 2.9677 - acc: 0.0400\n",
      "Epoch 43/500\n",
      " - 0s - loss: 2.9557 - acc: 0.0400\n",
      "Epoch 44/500\n",
      " - 0s - loss: 2.9415 - acc: 0.0800\n",
      "Epoch 45/500\n",
      " - 0s - loss: 2.9294 - acc: 0.0800\n",
      "Epoch 46/500\n",
      " - 0s - loss: 2.9151 - acc: 0.0800\n",
      "Epoch 47/500\n",
      " - 0s - loss: 2.9023 - acc: 0.0400\n",
      "Epoch 48/500\n",
      " - 0s - loss: 2.8901 - acc: 0.0400\n",
      "Epoch 49/500\n",
      " - 0s - loss: 2.8767 - acc: 0.0400\n",
      "Epoch 50/500\n",
      " - 0s - loss: 2.8633 - acc: 0.0400\n",
      "Epoch 51/500\n",
      " - 0s - loss: 2.8508 - acc: 0.0400\n",
      "Epoch 52/500\n",
      " - 0s - loss: 2.8380 - acc: 0.0400\n",
      "Epoch 53/500\n",
      " - 0s - loss: 2.8255 - acc: 0.0800\n",
      "Epoch 54/500\n",
      " - 0s - loss: 2.8133 - acc: 0.0400\n",
      "Epoch 55/500\n",
      " - 0s - loss: 2.8025 - acc: 0.0400\n",
      "Epoch 56/500\n",
      " - 0s - loss: 2.7889 - acc: 0.0800\n",
      "Epoch 57/500\n",
      " - 0s - loss: 2.7788 - acc: 0.0800\n",
      "Epoch 58/500\n",
      " - 0s - loss: 2.7669 - acc: 0.0800\n",
      "Epoch 59/500\n",
      " - 0s - loss: 2.7560 - acc: 0.0800\n",
      "Epoch 60/500\n",
      " - 0s - loss: 2.7464 - acc: 0.0800\n",
      "Epoch 61/500\n",
      " - 0s - loss: 2.7344 - acc: 0.1200\n",
      "Epoch 62/500\n",
      " - 0s - loss: 2.7249 - acc: 0.1200\n",
      "Epoch 63/500\n",
      " - 0s - loss: 2.7156 - acc: 0.1200\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.7058 - acc: 0.1200\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.6977 - acc: 0.1200\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.6882 - acc: 0.1200\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.6786 - acc: 0.1200\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.6713 - acc: 0.1200\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.6622 - acc: 0.1200\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.6550 - acc: 0.1200\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.6475 - acc: 0.0800\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.6393 - acc: 0.1200\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.6319 - acc: 0.1200\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.6241 - acc: 0.1200\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.6183 - acc: 0.1200\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.6111 - acc: 0.1200\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.6038 - acc: 0.0800\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.5980 - acc: 0.0800\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.5915 - acc: 0.1200\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.5842 - acc: 0.1200\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.5779 - acc: 0.1200\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.5696 - acc: 0.1200\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.5653 - acc: 0.1200\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.5592 - acc: 0.0800\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.5535 - acc: 0.1200\n",
      "Epoch 86/500\n",
      " - 0s - loss: 2.5472 - acc: 0.1200\n",
      "Epoch 87/500\n",
      " - 0s - loss: 2.5410 - acc: 0.1200\n",
      "Epoch 88/500\n",
      " - 0s - loss: 2.5354 - acc: 0.1200\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.5292 - acc: 0.1200\n",
      "Epoch 90/500\n",
      " - 0s - loss: 2.5226 - acc: 0.0800\n",
      "Epoch 91/500\n",
      " - 0s - loss: 2.5172 - acc: 0.1200\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.5123 - acc: 0.1200\n",
      "Epoch 93/500\n",
      " - 0s - loss: 2.5077 - acc: 0.1200\n",
      "Epoch 94/500\n",
      " - 0s - loss: 2.5004 - acc: 0.1200\n",
      "Epoch 95/500\n",
      " - 0s - loss: 2.4939 - acc: 0.1600\n",
      "Epoch 96/500\n",
      " - 0s - loss: 2.4897 - acc: 0.1600\n",
      "Epoch 97/500\n",
      " - 0s - loss: 2.4828 - acc: 0.1600\n",
      "Epoch 98/500\n",
      " - 0s - loss: 2.4788 - acc: 0.1600\n",
      "Epoch 99/500\n",
      " - 0s - loss: 2.4721 - acc: 0.1600\n",
      "Epoch 100/500\n",
      " - 0s - loss: 2.4677 - acc: 0.1600\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2.4619 - acc: 0.1600\n",
      "Epoch 102/500\n",
      " - 0s - loss: 2.4569 - acc: 0.1600\n",
      "Epoch 103/500\n",
      " - 0s - loss: 2.4510 - acc: 0.1600\n",
      "Epoch 104/500\n",
      " - 0s - loss: 2.4459 - acc: 0.1600\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.4403 - acc: 0.1600\n",
      "Epoch 106/500\n",
      " - 0s - loss: 2.4358 - acc: 0.2000\n",
      "Epoch 107/500\n",
      " - 0s - loss: 2.4313 - acc: 0.2000\n",
      "Epoch 108/500\n",
      " - 0s - loss: 2.4246 - acc: 0.2000\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.4208 - acc: 0.2000\n",
      "Epoch 110/500\n",
      " - 0s - loss: 2.4151 - acc: 0.2400\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.4105 - acc: 0.2000\n",
      "Epoch 112/500\n",
      " - 0s - loss: 2.4062 - acc: 0.2000\n",
      "Epoch 113/500\n",
      " - 0s - loss: 2.4011 - acc: 0.2000\n",
      "Epoch 114/500\n",
      " - 0s - loss: 2.3951 - acc: 0.2000\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.3927 - acc: 0.2000\n",
      "Epoch 116/500\n",
      " - 0s - loss: 2.3872 - acc: 0.2000\n",
      "Epoch 117/500\n",
      " - 0s - loss: 2.3825 - acc: 0.2000\n",
      "Epoch 118/500\n",
      " - 0s - loss: 2.3780 - acc: 0.2000\n",
      "Epoch 119/500\n",
      " - 0s - loss: 2.3738 - acc: 0.2800\n",
      "Epoch 120/500\n",
      " - 0s - loss: 2.3702 - acc: 0.2800\n",
      "Epoch 121/500\n",
      " - 0s - loss: 2.3655 - acc: 0.2400\n",
      "Epoch 122/500\n",
      " - 0s - loss: 2.3603 - acc: 0.2800\n",
      "Epoch 123/500\n",
      " - 0s - loss: 2.3550 - acc: 0.3200\n",
      "Epoch 124/500\n",
      " - 0s - loss: 2.3505 - acc: 0.2800\n",
      "Epoch 125/500\n",
      " - 0s - loss: 2.3476 - acc: 0.2800\n",
      "Epoch 126/500\n",
      " - 0s - loss: 2.3418 - acc: 0.2400\n",
      "Epoch 127/500\n",
      " - 0s - loss: 2.3373 - acc: 0.2000\n",
      "Epoch 128/500\n",
      " - 0s - loss: 2.3327 - acc: 0.2800\n",
      "Epoch 129/500\n",
      " - 0s - loss: 2.3288 - acc: 0.2000\n",
      "Epoch 130/500\n",
      " - 0s - loss: 2.3248 - acc: 0.2800\n",
      "Epoch 131/500\n",
      " - 0s - loss: 2.3207 - acc: 0.2400\n",
      "Epoch 132/500\n",
      " - 0s - loss: 2.3158 - acc: 0.2400\n",
      "Epoch 133/500\n",
      " - 0s - loss: 2.3128 - acc: 0.3200\n",
      "Epoch 134/500\n",
      " - 0s - loss: 2.3082 - acc: 0.2800\n",
      "Epoch 135/500\n",
      " - 0s - loss: 2.3044 - acc: 0.2800\n",
      "Epoch 136/500\n",
      " - 0s - loss: 2.3005 - acc: 0.2800\n",
      "Epoch 137/500\n",
      " - 0s - loss: 2.2953 - acc: 0.2800\n",
      "Epoch 138/500\n",
      " - 0s - loss: 2.2916 - acc: 0.2400\n",
      "Epoch 139/500\n",
      " - 0s - loss: 2.2874 - acc: 0.2800\n",
      "Epoch 140/500\n",
      " - 0s - loss: 2.2844 - acc: 0.2000\n",
      "Epoch 141/500\n",
      " - 0s - loss: 2.2803 - acc: 0.2400\n",
      "Epoch 142/500\n",
      " - 0s - loss: 2.2762 - acc: 0.2400\n",
      "Epoch 143/500\n",
      " - 0s - loss: 2.2736 - acc: 0.2800\n",
      "Epoch 144/500\n",
      " - 0s - loss: 2.2687 - acc: 0.2800\n",
      "Epoch 145/500\n",
      " - 0s - loss: 2.2657 - acc: 0.3200\n",
      "Epoch 146/500\n",
      " - 0s - loss: 2.2612 - acc: 0.2800\n",
      "Epoch 147/500\n",
      " - 0s - loss: 2.2573 - acc: 0.2400\n",
      "Epoch 148/500\n",
      " - 0s - loss: 2.2554 - acc: 0.1600\n",
      "Epoch 149/500\n",
      " - 0s - loss: 2.2499 - acc: 0.2000\n",
      "Epoch 150/500\n",
      " - 0s - loss: 2.2465 - acc: 0.2000\n",
      "Epoch 151/500\n",
      " - 0s - loss: 2.2434 - acc: 0.2800\n",
      "Epoch 152/500\n",
      " - 0s - loss: 2.2415 - acc: 0.2800\n",
      "Epoch 153/500\n",
      " - 0s - loss: 2.2356 - acc: 0.2000\n",
      "Epoch 154/500\n",
      " - 0s - loss: 2.2341 - acc: 0.2400\n",
      "Epoch 155/500\n",
      " - 0s - loss: 2.2300 - acc: 0.2800\n",
      "Epoch 156/500\n",
      " - 0s - loss: 2.2273 - acc: 0.2000\n",
      "Epoch 157/500\n",
      " - 0s - loss: 2.2224 - acc: 0.2800\n",
      "Epoch 158/500\n",
      " - 0s - loss: 2.2203 - acc: 0.2000\n",
      "Epoch 159/500\n",
      " - 0s - loss: 2.2152 - acc: 0.2800\n",
      "Epoch 160/500\n",
      " - 0s - loss: 2.2131 - acc: 0.2400\n",
      "Epoch 161/500\n",
      " - 0s - loss: 2.2099 - acc: 0.3200\n",
      "Epoch 162/500\n",
      " - 0s - loss: 2.2064 - acc: 0.3600\n",
      "Epoch 163/500\n",
      " - 0s - loss: 2.2036 - acc: 0.2800\n",
      "Epoch 164/500\n",
      " - 0s - loss: 2.2020 - acc: 0.3600\n",
      "Epoch 165/500\n",
      " - 0s - loss: 2.1977 - acc: 0.2800\n",
      "Epoch 166/500\n",
      " - 0s - loss: 2.1940 - acc: 0.2800\n",
      "Epoch 167/500\n",
      " - 0s - loss: 2.1918 - acc: 0.2400\n",
      "Epoch 168/500\n",
      " - 0s - loss: 2.1878 - acc: 0.3200\n",
      "Epoch 169/500\n",
      " - 0s - loss: 2.1859 - acc: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/500\n",
      " - 0s - loss: 2.1809 - acc: 0.3200\n",
      "Epoch 171/500\n",
      " - 0s - loss: 2.1793 - acc: 0.3200\n",
      "Epoch 172/500\n",
      " - 0s - loss: 2.1762 - acc: 0.2400\n",
      "Epoch 173/500\n",
      " - 0s - loss: 2.1712 - acc: 0.3200\n",
      "Epoch 174/500\n",
      " - 0s - loss: 2.1686 - acc: 0.2800\n",
      "Epoch 175/500\n",
      " - 0s - loss: 2.1673 - acc: 0.2800\n",
      "Epoch 176/500\n",
      " - 0s - loss: 2.1626 - acc: 0.3200\n",
      "Epoch 177/500\n",
      " - 0s - loss: 2.1595 - acc: 0.3600\n",
      "Epoch 178/500\n",
      " - 0s - loss: 2.1578 - acc: 0.3200\n",
      "Epoch 179/500\n",
      " - 0s - loss: 2.1553 - acc: 0.3200\n",
      "Epoch 180/500\n",
      " - 0s - loss: 2.1526 - acc: 0.2800\n",
      "Epoch 181/500\n",
      " - 0s - loss: 2.1509 - acc: 0.2400\n",
      "Epoch 182/500\n",
      " - 0s - loss: 2.1462 - acc: 0.2800\n",
      "Epoch 183/500\n",
      " - 0s - loss: 2.1423 - acc: 0.4000\n",
      "Epoch 184/500\n",
      " - 0s - loss: 2.1408 - acc: 0.3600\n",
      "Epoch 185/500\n",
      " - 0s - loss: 2.1375 - acc: 0.2400\n",
      "Epoch 186/500\n",
      " - 0s - loss: 2.1370 - acc: 0.2400\n",
      "Epoch 187/500\n",
      " - 0s - loss: 2.1319 - acc: 0.4000\n",
      "Epoch 188/500\n",
      " - 0s - loss: 2.1295 - acc: 0.3600\n",
      "Epoch 189/500\n",
      " - 0s - loss: 2.1259 - acc: 0.2800\n",
      "Epoch 190/500\n",
      " - 0s - loss: 2.1233 - acc: 0.3600\n",
      "Epoch 191/500\n",
      " - 0s - loss: 2.1217 - acc: 0.3200\n",
      "Epoch 192/500\n",
      " - 0s - loss: 2.1192 - acc: 0.3200\n",
      "Epoch 193/500\n",
      " - 0s - loss: 2.1167 - acc: 0.3600\n",
      "Epoch 194/500\n",
      " - 0s - loss: 2.1133 - acc: 0.4000\n",
      "Epoch 195/500\n",
      " - 0s - loss: 2.1125 - acc: 0.3600\n",
      "Epoch 196/500\n",
      " - 0s - loss: 2.1092 - acc: 0.3600\n",
      "Epoch 197/500\n",
      " - 0s - loss: 2.1059 - acc: 0.3600\n",
      "Epoch 198/500\n",
      " - 0s - loss: 2.1031 - acc: 0.3600\n",
      "Epoch 199/500\n",
      " - 0s - loss: 2.1018 - acc: 0.3200\n",
      "Epoch 200/500\n",
      " - 0s - loss: 2.0988 - acc: 0.3200\n",
      "Epoch 201/500\n",
      " - 0s - loss: 2.0971 - acc: 0.4400\n",
      "Epoch 202/500\n",
      " - 0s - loss: 2.0942 - acc: 0.3200\n",
      "Epoch 203/500\n",
      " - 0s - loss: 2.0913 - acc: 0.4800\n",
      "Epoch 204/500\n",
      " - 0s - loss: 2.0883 - acc: 0.4400\n",
      "Epoch 205/500\n",
      " - 0s - loss: 2.0860 - acc: 0.5200\n",
      "Epoch 206/500\n",
      " - 0s - loss: 2.0849 - acc: 0.3600\n",
      "Epoch 207/500\n",
      " - 0s - loss: 2.0823 - acc: 0.4400\n",
      "Epoch 208/500\n",
      " - 0s - loss: 2.0789 - acc: 0.4400\n",
      "Epoch 209/500\n",
      " - 0s - loss: 2.0779 - acc: 0.3200\n",
      "Epoch 210/500\n",
      " - 0s - loss: 2.0748 - acc: 0.4000\n",
      "Epoch 211/500\n",
      " - 0s - loss: 2.0742 - acc: 0.3200\n",
      "Epoch 212/500\n",
      " - 0s - loss: 2.0730 - acc: 0.4800\n",
      "Epoch 213/500\n",
      " - 0s - loss: 2.0696 - acc: 0.4400\n",
      "Epoch 214/500\n",
      " - 0s - loss: 2.0664 - acc: 0.3600\n",
      "Epoch 215/500\n",
      " - 0s - loss: 2.0684 - acc: 0.4000\n",
      "Epoch 216/500\n",
      " - 0s - loss: 2.0635 - acc: 0.3600\n",
      "Epoch 217/500\n",
      " - 0s - loss: 2.0601 - acc: 0.4400\n",
      "Epoch 218/500\n",
      " - 0s - loss: 2.0577 - acc: 0.4400\n",
      "Epoch 219/500\n",
      " - 0s - loss: 2.0568 - acc: 0.3600\n",
      "Epoch 220/500\n",
      " - 0s - loss: 2.0545 - acc: 0.2800\n",
      "Epoch 221/500\n",
      " - 0s - loss: 2.0510 - acc: 0.4000\n",
      "Epoch 222/500\n",
      " - 0s - loss: 2.0503 - acc: 0.5200\n",
      "Epoch 223/500\n",
      " - 0s - loss: 2.0473 - acc: 0.3600\n",
      "Epoch 224/500\n",
      " - 0s - loss: 2.0470 - acc: 0.4800\n",
      "Epoch 225/500\n",
      " - 0s - loss: 2.0429 - acc: 0.4800\n",
      "Epoch 226/500\n",
      " - 0s - loss: 2.0419 - acc: 0.4400\n",
      "Epoch 227/500\n",
      " - 0s - loss: 2.0394 - acc: 0.4400\n",
      "Epoch 228/500\n",
      " - 0s - loss: 2.0369 - acc: 0.4400\n",
      "Epoch 229/500\n",
      " - 0s - loss: 2.0345 - acc: 0.5200\n",
      "Epoch 230/500\n",
      " - 0s - loss: 2.0338 - acc: 0.5600\n",
      "Epoch 231/500\n",
      " - 0s - loss: 2.0300 - acc: 0.4400\n",
      "Epoch 232/500\n",
      " - 0s - loss: 2.0285 - acc: 0.5200\n",
      "Epoch 233/500\n",
      " - 0s - loss: 2.0270 - acc: 0.4400\n",
      "Epoch 234/500\n",
      " - 0s - loss: 2.0246 - acc: 0.5200\n",
      "Epoch 235/500\n",
      " - 0s - loss: 2.0221 - acc: 0.4800\n",
      "Epoch 236/500\n",
      " - 0s - loss: 2.0216 - acc: 0.4800\n",
      "Epoch 237/500\n",
      " - 0s - loss: 2.0187 - acc: 0.4800\n",
      "Epoch 238/500\n",
      " - 0s - loss: 2.0173 - acc: 0.3600\n",
      "Epoch 239/500\n",
      " - 0s - loss: 2.0157 - acc: 0.3600\n",
      "Epoch 240/500\n",
      " - 0s - loss: 2.0126 - acc: 0.3600\n",
      "Epoch 241/500\n",
      " - 0s - loss: 2.0139 - acc: 0.4800\n",
      "Epoch 242/500\n",
      " - 0s - loss: 2.0103 - acc: 0.4400\n",
      "Epoch 243/500\n",
      " - 0s - loss: 2.0075 - acc: 0.4400\n",
      "Epoch 244/500\n",
      " - 0s - loss: 2.0039 - acc: 0.4800\n",
      "Epoch 245/500\n",
      " - 0s - loss: 2.0042 - acc: 0.4800\n",
      "Epoch 246/500\n",
      " - 0s - loss: 2.0022 - acc: 0.5200\n",
      "Epoch 247/500\n",
      " - 0s - loss: 1.9994 - acc: 0.4800\n",
      "Epoch 248/500\n",
      " - 0s - loss: 1.9977 - acc: 0.5200\n",
      "Epoch 249/500\n",
      " - 0s - loss: 1.9959 - acc: 0.4800\n",
      "Epoch 250/500\n",
      " - 0s - loss: 1.9950 - acc: 0.5200\n",
      "Epoch 251/500\n",
      " - 0s - loss: 1.9911 - acc: 0.4800\n",
      "Epoch 252/500\n",
      " - 0s - loss: 1.9889 - acc: 0.4800\n",
      "Epoch 253/500\n",
      " - 0s - loss: 1.9891 - acc: 0.5200\n",
      "Epoch 254/500\n",
      " - 0s - loss: 1.9871 - acc: 0.5200\n",
      "Epoch 255/500\n",
      " - 0s - loss: 1.9842 - acc: 0.4400\n",
      "Epoch 256/500\n",
      " - 0s - loss: 1.9820 - acc: 0.5200\n",
      "Epoch 257/500\n",
      " - 0s - loss: 1.9820 - acc: 0.4800\n",
      "Epoch 258/500\n",
      " - 0s - loss: 1.9791 - acc: 0.5200\n",
      "Epoch 259/500\n",
      " - 0s - loss: 1.9769 - acc: 0.4800\n",
      "Epoch 260/500\n",
      " - 0s - loss: 1.9760 - acc: 0.4800\n",
      "Epoch 261/500\n",
      " - 0s - loss: 1.9737 - acc: 0.6400\n",
      "Epoch 262/500\n",
      " - 0s - loss: 1.9736 - acc: 0.4800\n",
      "Epoch 263/500\n",
      " - 0s - loss: 1.9699 - acc: 0.4000\n",
      "Epoch 264/500\n",
      " - 0s - loss: 1.9693 - acc: 0.5600\n",
      "Epoch 265/500\n",
      " - 0s - loss: 1.9651 - acc: 0.5600\n",
      "Epoch 266/500\n",
      " - 0s - loss: 1.9666 - acc: 0.5200\n",
      "Epoch 267/500\n",
      " - 0s - loss: 1.9641 - acc: 0.5200\n",
      "Epoch 268/500\n",
      " - 0s - loss: 1.9604 - acc: 0.5600\n",
      "Epoch 269/500\n",
      " - 0s - loss: 1.9586 - acc: 0.6000\n",
      "Epoch 270/500\n",
      " - 0s - loss: 1.9587 - acc: 0.5600\n",
      "Epoch 271/500\n",
      " - 0s - loss: 1.9568 - acc: 0.4800\n",
      "Epoch 272/500\n",
      " - 0s - loss: 1.9534 - acc: 0.4400\n",
      "Epoch 273/500\n",
      " - 0s - loss: 1.9522 - acc: 0.4800\n",
      "Epoch 274/500\n",
      " - 0s - loss: 1.9529 - acc: 0.5600\n",
      "Epoch 275/500\n",
      " - 0s - loss: 1.9505 - acc: 0.5200\n",
      "Epoch 276/500\n",
      " - 0s - loss: 1.9477 - acc: 0.5600\n",
      "Epoch 277/500\n",
      " - 0s - loss: 1.9445 - acc: 0.5600\n",
      "Epoch 278/500\n",
      " - 0s - loss: 1.9439 - acc: 0.4000\n",
      "Epoch 279/500\n",
      " - 0s - loss: 1.9436 - acc: 0.4400\n",
      "Epoch 280/500\n",
      " - 0s - loss: 1.9412 - acc: 0.4400\n",
      "Epoch 281/500\n",
      " - 0s - loss: 1.9387 - acc: 0.4800\n",
      "Epoch 282/500\n",
      " - 0s - loss: 1.9382 - acc: 0.6000\n",
      "Epoch 283/500\n",
      " - 0s - loss: 1.9344 - acc: 0.5600\n",
      "Epoch 284/500\n",
      " - 0s - loss: 1.9356 - acc: 0.6400\n",
      "Epoch 285/500\n",
      " - 0s - loss: 1.9327 - acc: 0.6000\n",
      "Epoch 286/500\n",
      " - 0s - loss: 1.9309 - acc: 0.5200\n",
      "Epoch 287/500\n",
      " - 0s - loss: 1.9295 - acc: 0.6000\n",
      "Epoch 288/500\n",
      " - 0s - loss: 1.9273 - acc: 0.5600\n",
      "Epoch 289/500\n",
      " - 0s - loss: 1.9260 - acc: 0.5600\n",
      "Epoch 290/500\n",
      " - 0s - loss: 1.9242 - acc: 0.5200\n",
      "Epoch 291/500\n",
      " - 0s - loss: 1.9218 - acc: 0.4800\n",
      "Epoch 292/500\n",
      " - 0s - loss: 1.9200 - acc: 0.6800\n",
      "Epoch 293/500\n",
      " - 0s - loss: 1.9208 - acc: 0.5200\n",
      "Epoch 294/500\n",
      " - 0s - loss: 1.9191 - acc: 0.6400\n",
      "Epoch 295/500\n",
      " - 0s - loss: 1.9167 - acc: 0.6000\n",
      "Epoch 296/500\n",
      " - 0s - loss: 1.9157 - acc: 0.6000\n",
      "Epoch 297/500\n",
      " - 0s - loss: 1.9128 - acc: 0.6000\n",
      "Epoch 298/500\n",
      " - 0s - loss: 1.9116 - acc: 0.6000\n",
      "Epoch 299/500\n",
      " - 0s - loss: 1.9102 - acc: 0.6000\n",
      "Epoch 300/500\n",
      " - 0s - loss: 1.9095 - acc: 0.6000\n",
      "Epoch 301/500\n",
      " - 0s - loss: 1.9057 - acc: 0.5600\n",
      "Epoch 302/500\n",
      " - 0s - loss: 1.9061 - acc: 0.6000\n",
      "Epoch 303/500\n",
      " - 0s - loss: 1.9044 - acc: 0.6400\n",
      "Epoch 304/500\n",
      " - 0s - loss: 1.9024 - acc: 0.5200\n",
      "Epoch 305/500\n",
      " - 0s - loss: 1.9009 - acc: 0.5600\n",
      "Epoch 306/500\n",
      " - 0s - loss: 1.8990 - acc: 0.6000\n",
      "Epoch 307/500\n",
      " - 0s - loss: 1.8963 - acc: 0.6000\n",
      "Epoch 308/500\n",
      " - 0s - loss: 1.8978 - acc: 0.7200\n",
      "Epoch 309/500\n",
      " - 0s - loss: 1.8942 - acc: 0.6400\n",
      "Epoch 310/500\n",
      " - 0s - loss: 1.8948 - acc: 0.7200\n",
      "Epoch 311/500\n",
      " - 0s - loss: 1.8910 - acc: 0.6400\n",
      "Epoch 312/500\n",
      " - 0s - loss: 1.8901 - acc: 0.5600\n",
      "Epoch 313/500\n",
      " - 0s - loss: 1.8884 - acc: 0.6000\n",
      "Epoch 314/500\n",
      " - 0s - loss: 1.8867 - acc: 0.6000\n",
      "Epoch 315/500\n",
      " - 0s - loss: 1.8873 - acc: 0.6000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 1.8849 - acc: 0.6800\n",
      "Epoch 317/500\n",
      " - 0s - loss: 1.8846 - acc: 0.5600\n",
      "Epoch 318/500\n",
      " - 0s - loss: 1.8803 - acc: 0.6000\n",
      "Epoch 319/500\n",
      " - 0s - loss: 1.8793 - acc: 0.6800\n",
      "Epoch 320/500\n",
      " - 0s - loss: 1.8780 - acc: 0.6000\n",
      "Epoch 321/500\n",
      " - 0s - loss: 1.8771 - acc: 0.6800\n",
      "Epoch 322/500\n",
      " - 0s - loss: 1.8760 - acc: 0.7200\n",
      "Epoch 323/500\n",
      " - 0s - loss: 1.8731 - acc: 0.7200\n",
      "Epoch 324/500\n",
      " - 0s - loss: 1.8724 - acc: 0.7200\n",
      "Epoch 325/500\n",
      " - 0s - loss: 1.8707 - acc: 0.7200\n",
      "Epoch 326/500\n",
      " - 0s - loss: 1.8712 - acc: 0.6800\n",
      "Epoch 327/500\n",
      " - 0s - loss: 1.8680 - acc: 0.6800\n",
      "Epoch 328/500\n",
      " - 0s - loss: 1.8678 - acc: 0.6800\n",
      "Epoch 329/500\n",
      " - 0s - loss: 1.8667 - acc: 0.7200\n",
      "Epoch 330/500\n",
      " - 0s - loss: 1.8637 - acc: 0.7200\n",
      "Epoch 331/500\n",
      " - 0s - loss: 1.8636 - acc: 0.6400\n",
      "Epoch 332/500\n",
      " - 0s - loss: 1.8621 - acc: 0.7200\n",
      "Epoch 333/500\n",
      " - 0s - loss: 1.8595 - acc: 0.7200\n",
      "Epoch 334/500\n",
      " - 0s - loss: 1.8562 - acc: 0.7600\n",
      "Epoch 335/500\n",
      " - 0s - loss: 1.8568 - acc: 0.6400\n",
      "Epoch 336/500\n",
      " - 0s - loss: 1.8550 - acc: 0.6000\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.8547 - acc: 0.6400\n",
      "Epoch 338/500\n",
      " - 0s - loss: 1.8543 - acc: 0.6400\n",
      "Epoch 339/500\n",
      " - 0s - loss: 1.8515 - acc: 0.7600\n",
      "Epoch 340/500\n",
      " - 0s - loss: 1.8505 - acc: 0.6400\n",
      "Epoch 341/500\n",
      " - 0s - loss: 1.8491 - acc: 0.6400\n",
      "Epoch 342/500\n",
      " - 0s - loss: 1.8476 - acc: 0.5600\n",
      "Epoch 343/500\n",
      " - 0s - loss: 1.8474 - acc: 0.6800\n",
      "Epoch 344/500\n",
      " - 0s - loss: 1.8478 - acc: 0.7200\n",
      "Epoch 345/500\n",
      " - 0s - loss: 1.8475 - acc: 0.6800\n",
      "Epoch 346/500\n",
      " - 0s - loss: 1.8417 - acc: 0.6800\n",
      "Epoch 347/500\n",
      " - 0s - loss: 1.8409 - acc: 0.7200\n",
      "Epoch 348/500\n",
      " - 0s - loss: 1.8394 - acc: 0.6400\n",
      "Epoch 349/500\n",
      " - 0s - loss: 1.8400 - acc: 0.6800\n",
      "Epoch 350/500\n",
      " - 0s - loss: 1.8379 - acc: 0.7200\n",
      "Epoch 351/500\n",
      " - 0s - loss: 1.8347 - acc: 0.7600\n",
      "Epoch 352/500\n",
      " - 0s - loss: 1.8343 - acc: 0.6800\n",
      "Epoch 353/500\n",
      " - 0s - loss: 1.8355 - acc: 0.6800\n",
      "Epoch 354/500\n",
      " - 0s - loss: 1.8317 - acc: 0.6800\n",
      "Epoch 355/500\n",
      " - 0s - loss: 1.8309 - acc: 0.7600\n",
      "Epoch 356/500\n",
      " - 0s - loss: 1.8303 - acc: 0.6800\n",
      "Epoch 357/500\n",
      " - 0s - loss: 1.8291 - acc: 0.6400\n",
      "Epoch 358/500\n",
      " - 0s - loss: 1.8280 - acc: 0.6800\n",
      "Epoch 359/500\n",
      " - 0s - loss: 1.8259 - acc: 0.7600\n",
      "Epoch 360/500\n",
      " - 0s - loss: 1.8236 - acc: 0.7600\n",
      "Epoch 361/500\n",
      " - 0s - loss: 1.8233 - acc: 0.6800\n",
      "Epoch 362/500\n",
      " - 0s - loss: 1.8217 - acc: 0.7200\n",
      "Epoch 363/500\n",
      " - 0s - loss: 1.8236 - acc: 0.7200\n",
      "Epoch 364/500\n",
      " - 0s - loss: 1.8193 - acc: 0.6400\n",
      "Epoch 365/500\n",
      " - 0s - loss: 1.8188 - acc: 0.7200\n",
      "Epoch 366/500\n",
      " - 0s - loss: 1.8168 - acc: 0.7200\n",
      "Epoch 367/500\n",
      " - 0s - loss: 1.8171 - acc: 0.8000\n",
      "Epoch 368/500\n",
      " - 0s - loss: 1.8146 - acc: 0.6800\n",
      "Epoch 369/500\n",
      " - 0s - loss: 1.8142 - acc: 0.7200\n",
      "Epoch 370/500\n",
      " - 0s - loss: 1.8136 - acc: 0.7200\n",
      "Epoch 371/500\n",
      " - 0s - loss: 1.8104 - acc: 0.7200\n",
      "Epoch 372/500\n",
      " - 0s - loss: 1.8099 - acc: 0.7200\n",
      "Epoch 373/500\n",
      " - 0s - loss: 1.8083 - acc: 0.7600\n",
      "Epoch 374/500\n",
      " - 0s - loss: 1.8077 - acc: 0.6800\n",
      "Epoch 375/500\n",
      " - 0s - loss: 1.8077 - acc: 0.6400\n",
      "Epoch 376/500\n",
      " - 0s - loss: 1.8051 - acc: 0.7600\n",
      "Epoch 377/500\n",
      " - 0s - loss: 1.8052 - acc: 0.7600\n",
      "Epoch 378/500\n",
      " - 0s - loss: 1.8032 - acc: 0.7200\n",
      "Epoch 379/500\n",
      " - 0s - loss: 1.8007 - acc: 0.6800\n",
      "Epoch 380/500\n",
      " - 0s - loss: 1.7998 - acc: 0.7200\n",
      "Epoch 381/500\n",
      " - 0s - loss: 1.7987 - acc: 0.6800\n",
      "Epoch 382/500\n",
      " - 0s - loss: 1.7965 - acc: 0.7600\n",
      "Epoch 383/500\n",
      " - 0s - loss: 1.7979 - acc: 0.6800\n",
      "Epoch 384/500\n",
      " - 0s - loss: 1.7965 - acc: 0.7600\n",
      "Epoch 385/500\n",
      " - 0s - loss: 1.7960 - acc: 0.7600\n",
      "Epoch 386/500\n",
      " - 0s - loss: 1.7916 - acc: 0.7200\n",
      "Epoch 387/500\n",
      " - 0s - loss: 1.7919 - acc: 0.6800\n",
      "Epoch 388/500\n",
      " - 0s - loss: 1.7916 - acc: 0.6400\n",
      "Epoch 389/500\n",
      " - 0s - loss: 1.7921 - acc: 0.7200\n",
      "Epoch 390/500\n",
      " - 0s - loss: 1.7878 - acc: 0.7200\n",
      "Epoch 391/500\n",
      " - 0s - loss: 1.7896 - acc: 0.7600\n",
      "Epoch 392/500\n",
      " - 0s - loss: 1.7862 - acc: 0.7600\n",
      "Epoch 393/500\n",
      " - 0s - loss: 1.7873 - acc: 0.8000\n",
      "Epoch 394/500\n",
      " - 0s - loss: 1.7833 - acc: 0.7600\n",
      "Epoch 395/500\n",
      " - 0s - loss: 1.7825 - acc: 0.6800\n",
      "Epoch 396/500\n",
      " - 0s - loss: 1.7818 - acc: 0.6000\n",
      "Epoch 397/500\n",
      " - 0s - loss: 1.7800 - acc: 0.7600\n",
      "Epoch 398/500\n",
      " - 0s - loss: 1.7790 - acc: 0.7600\n",
      "Epoch 399/500\n",
      " - 0s - loss: 1.7789 - acc: 0.7600\n",
      "Epoch 400/500\n",
      " - 0s - loss: 1.7766 - acc: 0.7600\n",
      "Epoch 401/500\n",
      " - 0s - loss: 1.7769 - acc: 0.8000\n",
      "Epoch 402/500\n",
      " - 0s - loss: 1.7752 - acc: 0.7200\n",
      "Epoch 403/500\n",
      " - 0s - loss: 1.7772 - acc: 0.7200\n",
      "Epoch 404/500\n",
      " - 0s - loss: 1.7734 - acc: 0.8000\n",
      "Epoch 405/500\n",
      " - 0s - loss: 1.7715 - acc: 0.8000\n",
      "Epoch 406/500\n",
      " - 0s - loss: 1.7719 - acc: 0.7600\n",
      "Epoch 407/500\n",
      " - 0s - loss: 1.7727 - acc: 0.7200\n",
      "Epoch 408/500\n",
      " - 0s - loss: 1.7675 - acc: 0.7600\n",
      "Epoch 409/500\n",
      " - 0s - loss: 1.7680 - acc: 0.7200\n",
      "Epoch 410/500\n",
      " - 0s - loss: 1.7660 - acc: 0.7200\n",
      "Epoch 411/500\n",
      " - 0s - loss: 1.7693 - acc: 0.7600\n",
      "Epoch 412/500\n",
      " - 0s - loss: 1.7646 - acc: 0.7600\n",
      "Epoch 413/500\n",
      " - 0s - loss: 1.7639 - acc: 0.7600\n",
      "Epoch 414/500\n",
      " - 0s - loss: 1.7618 - acc: 0.7600\n",
      "Epoch 415/500\n",
      " - 0s - loss: 1.7619 - acc: 0.7200\n",
      "Epoch 416/500\n",
      " - 0s - loss: 1.7605 - acc: 0.8000\n",
      "Epoch 417/500\n",
      " - 0s - loss: 1.7592 - acc: 0.7600\n",
      "Epoch 418/500\n",
      " - 0s - loss: 1.7593 - acc: 0.6400\n",
      "Epoch 419/500\n",
      " - 0s - loss: 1.7548 - acc: 0.7600\n",
      "Epoch 420/500\n",
      " - 0s - loss: 1.7568 - acc: 0.7600\n",
      "Epoch 421/500\n",
      " - 0s - loss: 1.7558 - acc: 0.8000\n",
      "Epoch 422/500\n",
      " - 0s - loss: 1.7530 - acc: 0.8000\n",
      "Epoch 423/500\n",
      " - 0s - loss: 1.7529 - acc: 0.8000\n",
      "Epoch 424/500\n",
      " - 0s - loss: 1.7519 - acc: 0.8000\n",
      "Epoch 425/500\n",
      " - 0s - loss: 1.7511 - acc: 0.7600\n",
      "Epoch 426/500\n",
      " - 0s - loss: 1.7521 - acc: 0.8400\n",
      "Epoch 427/500\n",
      " - 0s - loss: 1.7493 - acc: 0.8000\n",
      "Epoch 428/500\n",
      " - 0s - loss: 1.7497 - acc: 0.7600\n",
      "Epoch 429/500\n",
      " - 0s - loss: 1.7510 - acc: 0.8400\n",
      "Epoch 430/500\n",
      " - 0s - loss: 1.7463 - acc: 0.8400\n",
      "Epoch 431/500\n",
      " - 0s - loss: 1.7437 - acc: 0.7600\n",
      "Epoch 432/500\n",
      " - 0s - loss: 1.7458 - acc: 0.7600\n",
      "Epoch 433/500\n",
      " - 0s - loss: 1.7411 - acc: 0.7600\n",
      "Epoch 434/500\n",
      " - 0s - loss: 1.7405 - acc: 0.8000\n",
      "Epoch 435/500\n",
      " - 0s - loss: 1.7417 - acc: 0.8000\n",
      "Epoch 436/500\n",
      " - 0s - loss: 1.7380 - acc: 0.8000\n",
      "Epoch 437/500\n",
      " - 0s - loss: 1.7395 - acc: 0.7600\n",
      "Epoch 438/500\n",
      " - 0s - loss: 1.7388 - acc: 0.8000\n",
      "Epoch 439/500\n",
      " - 0s - loss: 1.7368 - acc: 0.8400\n",
      "Epoch 440/500\n",
      " - 0s - loss: 1.7374 - acc: 0.8000\n",
      "Epoch 441/500\n",
      " - 0s - loss: 1.7334 - acc: 0.7600\n",
      "Epoch 442/500\n",
      " - 0s - loss: 1.7334 - acc: 0.7200\n",
      "Epoch 443/500\n",
      " - 0s - loss: 1.7312 - acc: 0.8000\n",
      "Epoch 444/500\n",
      " - 0s - loss: 1.7308 - acc: 0.8400\n",
      "Epoch 445/500\n",
      " - 0s - loss: 1.7308 - acc: 0.8000\n",
      "Epoch 446/500\n",
      " - 0s - loss: 1.7307 - acc: 0.7600\n",
      "Epoch 447/500\n",
      " - 0s - loss: 1.7282 - acc: 0.8000\n",
      "Epoch 448/500\n",
      " - 0s - loss: 1.7289 - acc: 0.7200\n",
      "Epoch 449/500\n",
      " - 0s - loss: 1.7268 - acc: 0.8000\n",
      "Epoch 450/500\n",
      " - 0s - loss: 1.7259 - acc: 0.8000\n",
      "Epoch 451/500\n",
      " - 0s - loss: 1.7239 - acc: 0.8000\n",
      "Epoch 452/500\n",
      " - 0s - loss: 1.7236 - acc: 0.7600\n",
      "Epoch 453/500\n",
      " - 0s - loss: 1.7218 - acc: 0.8000\n",
      "Epoch 454/500\n",
      " - 0s - loss: 1.7216 - acc: 0.8000\n",
      "Epoch 455/500\n",
      " - 0s - loss: 1.7200 - acc: 0.7200\n",
      "Epoch 456/500\n",
      " - 0s - loss: 1.7196 - acc: 0.8000\n",
      "Epoch 457/500\n",
      " - 0s - loss: 1.7213 - acc: 0.7600\n",
      "Epoch 458/500\n",
      " - 0s - loss: 1.7160 - acc: 0.8400\n",
      "Epoch 459/500\n",
      " - 0s - loss: 1.7147 - acc: 0.8400\n",
      "Epoch 460/500\n",
      " - 0s - loss: 1.7174 - acc: 0.8000\n",
      "Epoch 461/500\n",
      " - 0s - loss: 1.7163 - acc: 0.7600\n",
      "Epoch 462/500\n",
      " - 0s - loss: 1.7168 - acc: 0.7600\n",
      "Epoch 463/500\n",
      " - 0s - loss: 1.7136 - acc: 0.8000\n",
      "Epoch 464/500\n",
      " - 0s - loss: 1.7118 - acc: 0.8400\n",
      "Epoch 465/500\n",
      " - 0s - loss: 1.7136 - acc: 0.8000\n",
      "Epoch 466/500\n",
      " - 0s - loss: 1.7099 - acc: 0.7200\n",
      "Epoch 467/500\n",
      " - 0s - loss: 1.7088 - acc: 0.8000\n",
      "Epoch 468/500\n",
      " - 0s - loss: 1.7081 - acc: 0.8400\n",
      "Epoch 469/500\n",
      " - 0s - loss: 1.7064 - acc: 0.8000\n",
      "Epoch 470/500\n",
      " - 0s - loss: 1.7057 - acc: 0.8400\n",
      "Epoch 471/500\n",
      " - 0s - loss: 1.7071 - acc: 0.8400\n",
      "Epoch 472/500\n",
      " - 0s - loss: 1.7064 - acc: 0.8000\n",
      "Epoch 473/500\n",
      " - 0s - loss: 1.7026 - acc: 0.7600\n",
      "Epoch 474/500\n",
      " - 0s - loss: 1.7033 - acc: 0.7600\n",
      "Epoch 475/500\n",
      " - 0s - loss: 1.7031 - acc: 0.7200\n",
      "Epoch 476/500\n",
      " - 0s - loss: 1.7026 - acc: 0.8000\n",
      "Epoch 477/500\n",
      " - 0s - loss: 1.7004 - acc: 0.8400\n",
      "Epoch 478/500\n",
      " - 0s - loss: 1.6987 - acc: 0.7600\n",
      "Epoch 479/500\n",
      " - 0s - loss: 1.6987 - acc: 0.8400\n",
      "Epoch 480/500\n",
      " - 0s - loss: 1.6975 - acc: 0.8000\n",
      "Epoch 481/500\n",
      " - 0s - loss: 1.6951 - acc: 0.8000\n",
      "Epoch 482/500\n",
      " - 0s - loss: 1.6965 - acc: 0.8000\n",
      "Epoch 483/500\n",
      " - 0s - loss: 1.6943 - acc: 0.8800\n",
      "Epoch 484/500\n",
      " - 0s - loss: 1.6958 - acc: 0.7200\n",
      "Epoch 485/500\n",
      " - 0s - loss: 1.6936 - acc: 0.8400\n",
      "Epoch 486/500\n",
      " - 0s - loss: 1.6936 - acc: 0.8000\n",
      "Epoch 487/500\n",
      " - 0s - loss: 1.6916 - acc: 0.8000\n",
      "Epoch 488/500\n",
      " - 0s - loss: 1.6892 - acc: 0.8800\n",
      "Epoch 489/500\n",
      " - 0s - loss: 1.6920 - acc: 0.8400\n",
      "Epoch 490/500\n",
      " - 0s - loss: 1.6874 - acc: 0.8400\n",
      "Epoch 491/500\n",
      " - 0s - loss: 1.6885 - acc: 0.7600\n",
      "Epoch 492/500\n",
      " - 0s - loss: 1.6884 - acc: 0.8000\n",
      "Epoch 493/500\n",
      " - 0s - loss: 1.6894 - acc: 0.8400\n",
      "Epoch 494/500\n",
      " - 0s - loss: 1.6863 - acc: 0.8400\n",
      "Epoch 495/500\n",
      " - 0s - loss: 1.6842 - acc: 0.8400\n",
      "Epoch 496/500\n",
      " - 0s - loss: 1.6819 - acc: 0.8800\n",
      "Epoch 497/500\n",
      " - 0s - loss: 1.6835 - acc: 0.7600\n",
      "Epoch 498/500\n",
      " - 0s - loss: 1.6826 - acc: 0.8000\n",
      "Epoch 499/500\n",
      " - 0s - loss: 1.6820 - acc: 0.8000\n",
      "Epoch 500/500\n",
      " - 0s - loss: 1.6815 - acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e3922acd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=500,batch_size=1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If predicting from data tensors, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e74083cd5216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1027\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             raise ValueError('If predicting from data tensors, '\n\u001b[0m\u001b[1;32m   1777\u001b[0m                              \u001b[0;34m'you should specify the `steps` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m                              'argument.')\n",
      "\u001b[0;31mValueError\u001b[0m: If predicting from data tensors, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "model.predict(char_to_int.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.array([\n",
    "    [20,30,None], # meaning: temperature1: 20, temperature2: 30, go-out: don't need this info\n",
    "    [23,32,None],\n",
    "    [24,23,1], # meaning: temperature1: 24, temperature2: 23, go-out: 1 (yes) \n",
    "    [26,30,1],\n",
    "    [20,20,0],\n",
    "    [30,32,0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = raw_data[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 30],\n",
       "       [23, 32],\n",
       "       [24, 23],\n",
       "       [26, 30],\n",
       "       [20, 20],\n",
       "       [30, 32]], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = raw_data[:,[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None],\n",
       "       [None],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in_window = np.array([[X[i], X[i+1]] for i in range(0,len(X) - 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[20, 30],\n",
       "         [23, 32]],\n",
       " \n",
       "        [[23, 32],\n",
       "         [24, 23]],\n",
       " \n",
       "        [[24, 23],\n",
       "         [26, 30]],\n",
       " \n",
       "        [[26, 30],\n",
       "         [20, 20]]], dtype=object), (4, 2, 2))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_in_window, X_in_window.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_in_window = np.array([Y[i + 2] for i in range(0,len(Y) - 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]], dtype=object), (4, 1))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in_window, y_in_window.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 10)                520       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 531\n",
      "Trainable params: 531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_weather = Sequential()\n",
    "model_weather.add(LSTM(10, input_shape=(X_in_window.shape[1],X_in_window.shape[2])))\n",
    "model_weather.add(Dense(1))\n",
    "model_weather.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model_weather.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_10_input to have shape (3, 2) but got array with shape (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1d0e870bf3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_weather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_in_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1427\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_10_input to have shape (3, 2) but got array with shape (2, 2)"
     ]
    }
   ],
   "source": [
    "model_weather.fit(X_in_window, y_in_window, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[20, 30],\n",
       "        [23, 32]],\n",
       "\n",
       "       [[23, 32],\n",
       "        [24, 23]],\n",
       "\n",
       "       [[24, 23],\n",
       "        [26, 30]],\n",
       "\n",
       "       [[26, 30],\n",
       "        [20, 20]]], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84493268]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weather.predict(np.array([[[20, 30],[24, 32]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
